{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.004499751189679 1.9980000836572827 5\n",
      "10.994500169476092\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#This program is just a rough reimplementation of linear regression in Python. It's not particularly\n",
    "#optimized in any way but it does give a sense of backpropagation, computing the loss function, and\n",
    "#updating the weights. The derivatives are taken numerically, instead of analytically. Numeric\n",
    "#derivatives are a bit slower and less intuitive, but do still work in this case.\n",
    "\n",
    "Xtrain = [1,2,3,4]\n",
    "Ytrain = [3,5,7,9]\n",
    "\n",
    "#Hyperparameters\n",
    "learningRate = .01\n",
    "numEpochs = 1000\n",
    "\n",
    "#In this case, our hypothesis is in the form of a model representing univariate \n",
    "#linear regression. y = theta0 + x*theta1\n",
    "def hypothesis(t0,t1,x):\n",
    "    return (t0  + t1*x)\n",
    "\n",
    "#Our loss function is the classic mean squared error form\n",
    "def costFunction(t0, t1):\n",
    "    loss = 0 \n",
    "    for i, j in zip(Xtrain,Ytrain):\n",
    "        temp = math.pow((hypothesis(t0,t1,i) - j),2)\n",
    "        loss += temp\n",
    "    return loss\n",
    "\n",
    "#Weight updates are done by taking the derivative of the loss function \n",
    "#with respect to each of the theta values. \n",
    "\n",
    "def weightUpdate(withRespectTo, t0, t1):\n",
    "    if(withRespectTo == 'theta0'):\n",
    "        t0 = t0 - learningRate * (derivative(withRespectTo, t0, t1))\n",
    "        return t0\n",
    "    else:\n",
    "        t1 = t1 - learningRate * (derivative(withRespectTo, t0, t1))\n",
    "        return t1\n",
    "\n",
    "#Evaluating a numerical deerivative    \n",
    "    \n",
    "def derivative(withRespectTo, t0, t1):\n",
    "    h  = 1./1000.\n",
    "    if(withRespectTo == 'theta0'):\n",
    "        rise = costFunction(t0 + h, t1) - costFunction(t0,t1)\n",
    "    else:\n",
    "        rise = costFunction(t0 , t1+h) - costFunction(t0,t1)\n",
    "    run = h\n",
    "    slope = rise/run\n",
    "    return slope\n",
    "\n",
    "#random initialization of values for theta\n",
    "theta0 = np.random.uniform(0,1)\n",
    "theta1 = np.random.uniform(0,1)\n",
    "#test value\n",
    "Xtest = 5\n",
    "for i in range(0,numEpochs):\n",
    "    theta0 = weightUpdate('theta0',theta0,theta1)\n",
    "    theta1 = weightUpdate('theta1',theta0,theta1)\n",
    "print(theta0,theta1,Xtest)\n",
    "print(hypothesis(theta0,theta1,Xtest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf_p3",
   "language": "python",
   "name": "keras_tf_p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, max_depth = 6, depth = 1):\n",
    "        self.max_depth = max_depth\n",
    "        self.depth = depth\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def fit(self, data, target):\n",
    "        if self.depth <= self.max_depth: print(f\"processing at Depth: {self.depth}\")\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.independent = self.data.columns.tolist()\n",
    "        self.independent.remove(target)\n",
    "        if self.depth <= self.max_depth:\n",
    "            self.__validate_data()\n",
    "            self.impurity_score = self.__calculate_impurity_score(self.data[self.target])\n",
    "            self.criteria, self.split_feature, self.information_gain = self.__find_best_split()\n",
    "            if self.criteria is not None and self.information_gain > 0: self.__create_branches()\n",
    "        else: \n",
    "            print(\"Stopping splitting as Max depth reached\")\n",
    "    \n",
    "    def __create_branches(self):\n",
    "        self.left = DecisionTree(max_depth = self.max_depth, \n",
    "                                 depth = self.depth + 1)\n",
    "        self.right = DecisionTree(max_depth = self.max_depth, \n",
    "                                 depth = self.depth + 1)\n",
    "        left_rows = self.data[self.data[self.split_feature] <= self.criteria] \n",
    "        right_rows = self.data[self.data[self.split_feature] > self.criteria] \n",
    "        self.left.fit(data = left_rows, target = self.target)\n",
    "        self.right.fit(data = right_rows, target = self.target)\n",
    "    \n",
    "    def __calculate_impurity_score(self, data):\n",
    "       if data is None or data.empty: return 0\n",
    "       p_i, _ = data.value_counts().apply(lambda x: x/len(data)).tolist() \n",
    "       return p_i * (1 - p_i) * 2\n",
    "    \n",
    "    def __find_best_split(self):\n",
    "        best_split = {}\n",
    "        for col in self.independent:\n",
    "            information_gain, split = self.__find_best_split_for_column(col)\n",
    "            if split is None: continue\n",
    "            if not best_split or best_split[\"information_gain\"] < information_gain:\n",
    "                best_split = {\"split\": split, \"col\": col, \"information_gain\": information_gain}\n",
    "\n",
    "        return best_split.get(\"split\"), best_split.get(\"col\"), best_split.get(\"information_gain\")\n",
    "\n",
    "    def __find_best_split_for_column(self, col):\n",
    "        x = self.data[col]\n",
    "        unique_values = x.unique()\n",
    "        if len(unique_values) == 1: return None, None\n",
    "        information_gain = None\n",
    "        split = None\n",
    "        for val in unique_values:\n",
    "            left = x <= val\n",
    "            right = x > val\n",
    "            left_data = self.data[left]\n",
    "            right_data = self.data[right]\n",
    "            left_impurity = self.__calculate_impurity_score(left_data[self.target])\n",
    "            right_impurity = self.__calculate_impurity_score(right_data[self.target])\n",
    "            score = self.__calculate_information_gain(left_count = len(left_data),\n",
    "                                                      left_impurity = left_impurity,\n",
    "                                                      right_count = len(right_data),\n",
    "                                                      right_impurity = right_impurity)\n",
    "            if information_gain is None or score > information_gain: \n",
    "                information_gain = score \n",
    "                split = val\n",
    "        return information_gain, split\n",
    "    \n",
    "    def __calculate_information_gain(self, left_count, left_impurity, right_count, right_impurity):\n",
    "        return self.impurity_score - ((left_count/len(self.data)) * left_impurity + \\\n",
    "                                      (right_count/len(self.data)) * right_impurity)\n",
    "\n",
    "    def predict(self, data):\n",
    "        return np.array([self.__flow_data_thru_tree(row) for _, row in data.iterrows()])\n",
    "\n",
    "    def __validate_data(self):\n",
    "        non_numeric_columns = self.data[self.independent].select_dtypes(include=['category', 'object', 'bool']).columns.tolist()\n",
    "        if(len(set(self.independent).intersection(set(non_numeric_columns))) != 0):\n",
    "            raise RuntimeError(\"Not all columns are numeric\")\n",
    "        \n",
    "        self.data[self.target] = self.data[self.target].astype(\"category\")\n",
    "        if(len(self.data[self.target].cat.categories) != 2):\n",
    "            raise RuntimeError(\"Implementation is only for Binary Classification\")\n",
    "\n",
    "    def __flow_data_thru_tree(self, row):\n",
    "        if self.is_leaf_node: return self.probability\n",
    "        tree = self.left if row[self.split_feature] <= self.criteria else self.right\n",
    "        return tree.__flow_data_thru_tree(row)\n",
    "        \n",
    "    @property\n",
    "    def is_leaf_node(self): return self.left is None\n",
    "\n",
    "    @property\n",
    "    def probability(self): \n",
    "        return self.data[self.target].value_counts().apply(lambda x: x/len(self.data)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from decision_tree import DecisionTree\n",
    "train = pd.read_csv('data/train_preprocessed.csv')\n",
    "test = pd.read_csv('data/test_preprocessed.csv')\n",
    "model = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data = train, target = \"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : https://lethalbrains.com/learn-ml-algorithms-by-coding-decision-trees-439ac503c9a4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf_p3",
   "language": "python",
   "name": "keras_tf_p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
